* nas
** ~search_space~: 搜索空间定义, 现在我实现的cnn和rnn的搜索空间都是cell-based, 不支持hierarchical. 兼容大多数(比较典型的: darts, enas)工作所用的search space.
** ~dataset~: 搜索数据集.
** ~rollout类型~: [2/3] (rollout是controller, ~weights_manager~, trainer都需要可知的interface class, 严格来说可能不能叫组件, 是组件中用于交流的object...)
[X] discrete: 描述采出来的架构 (e.g. nas, enas, mepa)
[X] differentiable: 描述采出来的架构, 但是会带上differentiable reparametrization的各种信息
 - hard sampling: 所描述的架构和discrete rollout描述的架构一样. 只是带上不同信息.
 - soft sampling: 不是sparse and discrete的arch, 而是和darts类似的, 对于每个输出节点, 每个op每个inputs都会有加权值. (e.g. darts, snas)
[x] mutation: 元组 ~(arch, mutation)~, 描述某个population里已经存在的arch上的改变. (e.g. most evolution-based methods, network-morphism based methods)
** ~controller~: 负责采样(sample)神经网络架构(arch); 在我的框架里, 称controller采出来的叫rollout, 现在实现了两种rollout类型, discrete和differentiable;
*** controller类型: 现在只实现了非population型的controller, 支持 *两种常用的回传梯度的方法* (/非population型的controller要解决的一个主要问题就是常见的怎么让梯度能够回传过采样出来的离散arch, 从而学习controller/) [2/4]
**** DONE rl: (discrete rollout)
***** 状态: rl network的参数
***** 采样: forward rnn
***** 学习: 使用RL agent 来"回传梯度"
***** check list:
****** controller rnn: anchor-based, embedding-based;
****** independent/dependent cell groups
****** RL agent:
[x] policy-gradient
[ ] PPO
[ ] A2C
**** DONE differentiable: (differentiable rollout)
***** 使用biased-path reparametrization-based方法来回传梯度, 现在用gumbel-softmax来实现.
***** 状态: global参数, 每个参数代表每个edge上不同op的概率
***** 采样: reparametrized sampling
***** 学习: backward through reparametrized expectation
***** check list: [2/3]
****** DONE soft sampling/hard sampling, 其中soft sampling兼容SNAS (在做了几周给darts加gumbel实验之后, 发现iclr2019商汤已经发了一篇给darts加gumbel的, 不过它搜出来的结果其实挺差, 都没有好好调; *纯nas现在性能的评价本身就是是个问题...*)
****** DONE 无采样, 即降级到1-order DARTS(darts的relaxation已经把采样概念都抹去, 是一种更加relax的relax, 这会导致最后的derive十分heuristic, 而且对于darts, ~每个独立arch的性能评价是否准确~ 这个评价很难做, 因为darts在搜索过程中都没有采样arch的概念)
****** TODO connection sampling: 现在不管是soft sampling还是hard sampling, cell里每个节点和前面节点的链接(connection)都是没有采样的. 直接用同一个分布i.i.d采需要的input 个数是不科学的. 假想一个最简单的情况: 对于某个节点, 有N=2个input node候选, 同时需要采M=2个input, 如果更好的架构就是两个input node要同时采到, 而不是容易两次采样都采到其中一个, 概率最好是(0.5, 0.5), 然而这显然不是一个好的概率, 因为即使这样仍然有1/2的几率会塌缩到只有一个input, 而且不管怎么学还不能让这个概率更小了... 所以要么直接建模联合分布(每个节点i的项有点多...C(Ni, M), 不一定好), 还没想好要怎么采...
**** TODO evolution based: (mutation rollout)
***** 状态: arch population(每个arch和其eval结果)
***** 采样: 根据一定的 选取(selection), 改变(mutation), 淘汰(aging) 机制来给出rollout
***** 学习: 存下arch和相应结果到population
**** TODO bayesian-optimization based: (mutation rollout)
***** prerequisite: 定义arch之间的距离(e.g. nas with bayesian optimization and optimal transport就是用optimal transport定义了两个离散arch之间的距离 OTMANN)
***** 状态: arch population(每个arch和其eval结果)
***** 采样: 用一些方法得到一堆candidate arch(e.g.从population选取一些arch做mutation), 使用bayesian模型(e.g. Gaussian Process)得到多个mutated candidate的expected performance(gp has different acquision function), 选择最大的作为输出arch
***** 学习: 存下arch和相应结果到population
** ~weights_manager~: 每个神经网络架构(arch)采出来之后, 需要评定其性能(performance), 但是每个arch从头训练到最后(e.g. 最早的NAS)太慢了, 所以很多工作都在关注如何加速每个arch的性能评定. 现在只实现了使用共享weights的方法(这也是现在最流行的方法, nas, enas, darts, mepa, snas). 但是在设计框架的时候考虑了其它可能的方法, 比如hypernet-based, network-morphism-based, 可以考虑加入. [1/2]
*** DONE shared-weights based (super network/graph): 针对discrete/differentiable rollout需要不同实现. 已实现 ~super_net~ 和 ~diff_super_net~ .
*** TODO network-morphism based: 只针对mutation rollout, 根据parent arch已训练网络的参数做一些尽量function-preserving改变作为初始参数
*** hypernet based: 训练一个hypernet从arch的离散表示生成初始化weights, 减少要训练的时间(我觉得蛮玄乎的, 可能不会实现这个)
*** TODO prediction-based evaluator: 每个arch评价不仅仅是走~O(1)个比较少的surrogate steps. 而是训好几个epoch, 做一些基于training curve extrapolation的performance prediction; 同时兼容不做performance prediction(这么做的工作也不少: original nas; 以及搭配了适当的weights manager做initilization不用训太多epoch的工作, 比如使用network-morhpism based/hyper-net based weights manager)
** ~trainer~: 负责orchestrate整个搜索(search)过程. [1/2]
*** DONE mepa trainer: 一个比较通用的和shared-weights weights manager一起工作的trainer(兼容enas, 无surrogate steps): 在更新shared super graph/net weights, 评价arch的performance的时候都会在一部分数据上运行几步训练(surrogate steps), 直观的理解: 可以认为这是从所有子网络(即所有不同arch)完全share weights(无surrogate training), 到每个arch独立训练到极致的, 是一种arch和weights的解耦合, 希望这样search过程对每个arch的performance评价会更准确.
**** 支持rollout: discrete, differentiable
**** 支持data类型: language, image (主要是评价标准不一样, perplexity vs. acc)
** 讨论:
****** 现在的代码支持比较多的方法, 并且因为合适的划分, 比这些方法有了更多的选项和组合的可能性 (包括并不限于enas, mepa, darts, snas...) 设计的时候也考虑了我知道的大多数nas方法. 有少数方法比较难统一, 比如更加general的hierarchical search space, 考虑过好一会, 但是实在有点不能统一到框架里. 暂时就用最通用的cell-based searchspace, 一般都有一定的meta-architecture假设, 比如第几层是reduction层需要stride=2, 前面层的output怎么连接到下一层的input)
****** Refactor code: trainer应该更加简化一点, 抽出evaluator(mepa, prediction)和objective... 比如trainer里最好不要涉及到根据 ~data_type~ 选择, 只需要负责调用 ~controller.sample~, ~weights_manager.assemble_candidate~, ~evaluator.get_perf/get_gradients~, ~weights_manager.update~, ~controller.update~. 管理interleave training配置这样的. 虽然现在也不是很乱吧, 但是讲道理 `做surrogate steps, 然后再evaluate得到performance/gradients' 这是要抽象出一个evaluator组件的... objective 可能还会有其它的指标, 比如硬件/latencey等, evaluator就只需要提供一个 ~get_gradients(candidate_arch)~ , 提供给基于shared weights的weights manager, 就可以和基于shared weights的weights manager一起工作. 另外还要提供 ~get_perf~ ~get_perf~ 会根据objective返回离散的结果. 还需要一个 ~objective~ 组件, 同时支持 ~multi-objective~.
